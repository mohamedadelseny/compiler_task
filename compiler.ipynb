{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d6d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical analysis failed: Invalid token at position 1:  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Token types\n",
    "token_patterns = [\n",
    "    ('LITERAL', r'\\d+'),\n",
    "    ('OPERATOR', r'[\\+\\-\\*/]'),\n",
    "    ('PUNCTUATION', r'[\\(\\)]')\n",
    "]\n",
    "\n",
    "\n",
    "def tokenize(expression):\n",
    "    tokens = []\n",
    "    position = 0\n",
    "\n",
    "    while position < len(expression):\n",
    "        match = None\n",
    "        for token_type, pattern in token_patterns:\n",
    "            regex = re.compile(pattern)\n",
    "            match = regex.match(expression, position)\n",
    "            if match:\n",
    "                lexeme = match.group(0)\n",
    "                tokens.append({'type': token_type, 'lexeme': lexeme})\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            position = match.end()\n",
    "        else:\n",
    "            invalid_char = expression[position]\n",
    "            raise ValueError(f'Invalid token at position {position}: {invalid_char}')\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def parse(tokens):\n",
    "    index = 0\n",
    "\n",
    "    def next_token():\n",
    "        nonlocal index\n",
    "        if index < len(tokens):\n",
    "            token = tokens[index]\n",
    "            index += 1\n",
    "            return token\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def expression():\n",
    "        token = next_token()\n",
    "        if token and token['type'] == 'OPERATOR' and token['lexeme'] == '+':\n",
    "            term()\n",
    "            expression()\n",
    "        else:\n",
    "            index -= 1\n",
    "\n",
    "    def term():\n",
    "        token = next_token()\n",
    "        if token and token['type'] == 'OPERATOR' and token['lexeme'] == '*':\n",
    "            factor()\n",
    "            term()\n",
    "        else:\n",
    "            index -= 1\n",
    "\n",
    "    def factor():\n",
    "        token = next_token()\n",
    "        if token and token['type'] == 'PUNCTUATION' and token['lexeme'] == '(':\n",
    "            expression()\n",
    "            token = next_token()\n",
    "            if token and token['type'] == 'PUNCTUATION' and token['lexeme'] == ')':\n",
    "                return\n",
    "            else:\n",
    "                raise ValueError('Syntax error: Missing closing parenthesis')\n",
    "        elif token and token['type'] == 'LITERAL':\n",
    "            return\n",
    "        else:\n",
    "            raise ValueError('Syntax error: Unexpected token')\n",
    "\n",
    "    expression()\n",
    "\n",
    "    if index != len(tokens):\n",
    "        raise ValueError('Syntax error: Extra tokens after parsing')\n",
    "\n",
    "\n",
    "# Example expression\n",
    "expression = '3 * (4 + @)'\n",
    "\n",
    "# Tokenize the expression\n",
    "try:\n",
    "    tokens = tokenize(expression)\n",
    "    print('Tokens:', tokens)\n",
    "\n",
    "    # Parse the tokens\n",
    "    try:\n",
    "        parse(tokens)\n",
    "        print('Syntax analysis successful')\n",
    "    except ValueError as e:\n",
    "        print('Syntax analysis failed:', str(e))\n",
    "except ValueError as e:\n",
    "    print('Lexical analysis failed:', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb415d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
